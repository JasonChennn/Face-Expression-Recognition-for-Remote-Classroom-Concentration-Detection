{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load emotions.py\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2, 3'\n",
    "\n",
    "# command line argument\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"--mode\",help=\"train/display\")\n",
    "mode = ap.parse_args().mode\n",
    "\n",
    "#Info\n",
    "postive_count = 0\n",
    "negative_count = 0\n",
    "\n",
    "# plots accuracy and loss curves\n",
    "def plot_model_history(model_history):\n",
    "    \"\"\"\n",
    "    Plot Accuracy and Loss curves given the model_history\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    fig.savefig('plot.png')\n",
    "    plt.show()\n",
    "\n",
    "# Define data generators\n",
    "train_dir = 'data/train'\n",
    "val_dir = 'data/test'\n",
    "\n",
    "num_train = 29690\n",
    "num_val = 8187\n",
    "batch_size = 64\n",
    "num_epoch = 100\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "def point(x):\n",
    "    return {\n",
    "        3: 5,\n",
    "        4: 5,\n",
    "        0: 3,\n",
    "        2: 3,\n",
    "        1: 1,\n",
    "        5: 1,\n",
    "        6: 1,\n",
    "        7: 1,\n",
    "    }[x]\n",
    "\n",
    "# If you want to train the same model or try other models, go for this\n",
    "if mode == \"train\":\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
    "    model_info = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=num_train // batch_size,\n",
    "            epochs=num_epoch,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=num_val // batch_size)\n",
    "    model.save_weights('model.h5')\n",
    "    plot_model_history(model_info)\n",
    "\n",
    "# emotions will be displayed on your face from the webcam feed\n",
    "elif mode == \"display\":\n",
    "    print(\"開始進行推論,結束時請按'q'來獲取專心程度結果.\")\n",
    "    model.load_weights('model.h5')\n",
    "\n",
    "    # prevents openCL usage and unnecessary logging messages\n",
    "    cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "    # dictionary which assigns each label an emotion (alphabetical order)\n",
    "    #emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "    emotion_dict = {0: \"Absent(-3)\", 1: \"Concentrate(1)\", 2: \"Concentrate(3)\", 3: \"Absent(-5)\", 4: \"Concentrate(5) \", 5: \"Absent(-1)\", 6: \"Concentrate(1)\", 7: \"Absent(-1)\"}\n",
    "\n",
    "    # start the webcam feed\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        # Find haar cascade to draw bounding box around face\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        facecasc = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = facecasc.detectMultiScale(gray,scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "            prediction = model.predict(cropped_img)\n",
    "            maxindex = int(np.argmax(prediction))\n",
    "            cv2.putText(frame, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            if(maxindex == 1 or maxindex == 2 or maxindex == 4 or maxindex == 6):\n",
    "                postive_count = postive_count + point(maxindex)\n",
    "            else:\n",
    "                negative_count = negative_count + point(maxindex)\n",
    "            print(\"人臉標籤Index:\" + maxindex + \"專心分數:\" + postive_count + \"不專心分數:\" + negative_count)\n",
    "\n",
    "        cv2.imshow('Video', cv2.resize(frame,(800,600),interpolation = cv2.INTER_CUBIC))\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    labels = 'Concentrate', 'Absent'\n",
    "    sizes = [postive_count/(postive_count+negative_count),negative_count/(postive_count+negative_count)]\n",
    "    explode = (0, 0.1) \n",
    "    plt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "    shadow=True, startangle=90)\n",
    "    if postive_count >= negative_count:\n",
    "        plt.title('Congrats! You are concentrate.')\n",
    "    else:\n",
    "        plt.title('Badly! You are absent.')\n",
    "    plt.axis('equal') \n",
    "    plt.show()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20e838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
